{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python39564bit549cf0b77a22421d935416dbb4c29b77",
   "display_name": "Python 3.9.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Felipe Bartelt de Assis Pessoa - 2016026841\n",
    "\n",
    "\n",
    "# Bases reais com ELMs\n",
    "## Breast Cancer\n",
    "### ELM\n",
    "\n",
    "A primeira base real utilizada foi a *Breast Cancer*, que é carregada por meio do seguinte trecho de código:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load dataset\n",
    "breast_cancer = load_breast_cancer()\n",
    "X_samples = breast_cancer['data']\n",
    "y_sample = np.reshape(breast_cancer['target'], (-1,1))"
   ]
  },
  {
   "source": [
    "\n",
    "Definiu-se as funções para treinamento de ELM `train_elm`, normalização de dados de entrada `normalize_features`, remoção de dados de entrada `delete_features` e avaliação de acurácia `eval_accuracy`. Essas funções são réplicas das já utilizadas nos exercícios anteriores, portanto não se vê como necessário explicação das mesmas. Ainda, foi feita uma modificação sobre a função `eval_accuracy`, uma vez que o treinamento de ELM se baseia na função de ativação $\\tanh(\\cdot)$, cuja imagem $\\in [-1,1]$, tem-se $(y_{test}-\\widehat{y})^2 = 4\\ \\forall y_{test}\\neq \\widehat{y}$, portanto foi adicionado um novo argumento `nn_type` que indica se a rede é ELM (`nn_type = 1`) ou perceptron (`nn_type = 0`), assim, o erro quadrático será dividido por $4$ caso a rede seja ELM.\n",
    "\n",
    "A divisão supracitada não ocorre justamente para redes ELM, mas sim com base na função de ativação, porém, uma vez que se implementou a ELM com função de ativação $\\tanh(\\cdot)$ e a rede perceptron com função de ativação logística, preferiu-se manter a notação baseada no tipo de rede visando tornar os argumentos do código mais uniformes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_elm(x_train, y_train, hidden_dim):\n",
    "    # Returns a weight vector based on sigmoidal mapping given by tanh\n",
    "    m = np.shape(x_train)[1]\n",
    "    Z = np.random.default_rng().uniform(-0.5, 0.5, (m, hidden_dim))\n",
    "    H = np.tanh(x_train @ Z)\n",
    "    W = np.linalg.pinv(H) @ y_train\n",
    "    return W, Z\n",
    "\n",
    "def normalize_features(X, mean, std):\n",
    "    Xtemp = np.copy(X)\n",
    "    Xtemp = Xtemp - mean\n",
    "    Xtemp = Xtemp / std\n",
    "    return Xtemp\n",
    "\n",
    "def delete_features(X, feat_idx):\n",
    "    # Returns matrix X with features indexes in feat_idx ignored\n",
    "    Xtemp = np.copy(X)\n",
    "    Xtemp = np.delete(Xtemp, feat_idx,1)\n",
    "    return Xtemp\n",
    "\n",
    "def eval_accuracy(y_hat, y, nn_type = 0):\n",
    "    # Divides quadratic error by 4 if activation function is tanh\n",
    "    N = np.shape(y)[0] * (4 ** nn_type)\n",
    "    return (1 - ((y-y_hat).T @ (y-y_hat)) / N).ravel()"
   ]
  },
  {
   "source": [
    "\n",
    "Definiu-se a função de treinamento do perceptron `train_perceptron` com base no método gradiente descendente, diferentemente do algoritmo implementado na Lista 3. Essa função tem como parâmetros os dados de entrada e saída `x_train, y_train`; o vetor de pesos inicial `init_w`, que, caso não fornecido, é iniciado como uma distribuição uniforme entre $[-\\epsilon,\\epsilon]$, onde $\\epsilon = \\frac{\\sqrt{6}}{\\sqrt{L_{in}+L_{out}}}$, sendo $L_{in}$ o número de neurônios na camada anterior e $L_{out}$ o número de neurônios da camada posterior; o passo do gradiente descendente `eta`, default $=0.1$; a tolerância `tol`, default = $10^{-5}$; e o número máximo de iterações para convergência `max_iter`, por default = $500$. Essa função retorna o vetor de pesos `w` com os valores ótimos obtidos.\n",
    "\n",
    "Para o funcionamento da função `train_perceptron`, definiu-se como função de custo, visando a convexidade, $J = -\\frac{1}{N}\\left(y^T\\ln{\\left(h(xw)\\right)}+(1-y^T)\\ln{\\left(1-h(xw)\\right)}\\right)$, cujo gradiente é $\\frac{\\partial J}{\\partial w} = \\frac{1}{N}\\left(x^T\\left(h\\left(xw\\right)-y\\right)\\right)$, sendo $x$ os dados de entrada, $y$ os dados de saída, $N$ o número de amostras e $h(\\cdot)$ a função sigmoidal logística: $h(u) = \\frac{1}{1+e^{-u}}$. \n",
    "\n",
    "Dessa forma, a função `cost_function` implementa justamente a função citada, tendo como parâmetros o vetor de pesos `weight_vector`, os dados de entrada e saída `input_samples, output_samples` e o parâmetro de regularização `reg_par`, cujo default $=0$. A função `sigmoid` implementa a função sigmoidal logística. A função `predict_label` retorna a classe aproximada, sendo $1\\text{ se } h(z)\\ge0.5,\\quad 0 \\text{ se } h(z)<0.5$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # Logistic function\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def cost_function(weigth_vector, input_samples, output_samples, reg_par = 0):\n",
    "    m = np.shape(input_samples)[0]\n",
    "    u = sigmoid(input_samples @ weigth_vector)\n",
    "    J = -1/m*(output_samples.T @ np.log(u) \n",
    "              + (1 - output_samples).T @ (np.log(1 - u))) + sum(reg_par/(2*m)*(weigth_vector[1::]**2))\n",
    "    return float(J.ravel())\n",
    "\n",
    "def predict_label(y):\n",
    "    # Return the label corresponding to sigmoid value\n",
    "    return 1*(y >= 0.5)\n",
    "\n",
    "def train_perceptron(x_train, y_train, init_w=None, eta=0.1, tol=1e-5, max_iter = 500):\n",
    "    # Minimize defined costfunction based on gradient descendent\n",
    "    N = np.shape(x_train)[0]\n",
    "\n",
    "    if init_w is None:\n",
    "        Lin, Lout = np.shape(x_train)[1], np.shape(y_train)[1]\n",
    "        epsilon = np.sqrt(6)/np.sqrt(Lin+Lout)\n",
    "        init_w = np.random.default_rng().uniform(-epsilon,epsilon,(Lin,Lout))\n",
    "    \n",
    "    w = init_w\n",
    "    itern, err = 0, tol+1\n",
    "    \n",
    "    while (itern < max_iter) and (abs(err) > tol):\n",
    "        y_hat = sigmoid(x_train @ w)\n",
    "        err = cost_function(w, x_train, y_train)\n",
    "        w = w - eta/N*(x_train.T @ (y_hat - y_train))\n",
    "        itern += 1\n",
    "    \n",
    "    return w\n"
   ]
  },
  {
   "source": [
    "\n",
    "Em seguida, altera-se as saídas nulas para $-1$, já que a rede ELM se baseia na função de ativação $\\tanh(\\cdot)$. Normaliza-se os dados de entrada e despreza-se os dados de entrada $2,3,9,11,12,13,14,18,19,22 \\text{ e } 23$, uma vez que, como já analisado anteriormente, esses dados não têm grande influência quanto à classe prevista ou representam combinação linear de outros dados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.shape(X_samples)[0]\n",
    "y_sample[y_sample==0] = -1\n",
    "\n",
    "# Normalize features\n",
    "X_mean = np.mean(X_samples, axis = 0)\n",
    "X_std = np.std(X_samples, axis = 0)\n",
    "X_samplen = normalize_features(X_samples, X_mean, X_std)\n",
    "\n",
    "# Remove useless features and append x0\n",
    "ignored_idx = [2,3,9,11,12,13,14,18,19,22,23]\n",
    "X_sample = delete_features(X_samplen, ignored_idx)\n",
    "X_sample = np.append(np.ones((N,1)), X_sample, 1)\n"
   ]
  },
  {
   "source": [
    "\n",
    "Uma vez que serão necessárias diversas iterações dos algoritmos, definiu-se a função `iterate_neuralnetwork`, que tem como argumentos os dados de entrada e saída `X_sample, y_sample`; o tipo de rede neural `nn_type` ($0=$ perceptron, $1=$ ELM); a lista de hiperparâmetros `hyper_params` para que se teste a rede ELM para diversos números de neurônios, default = $[1]$ e se a rede escolhida é do tipo *perceptron*, esse parâmetro é desconsiderado; o número de iterações `iter_num` desejadas para execução, de forma a se obter média e desvio padrão das acurácias obtidas nas iterações; e `eta`, o passo do algoritmo perceptron.\n",
    "\n",
    "O retorno dessa função são duas listas de tuplas, a primeira lista `acc_train_list` carrega as médias e desvio padrão, como tuplas, das acurácias obtidas para cada hiperparâmetro nos dados de treinamento, a outra lista `acc_train_list` traz as mesmas informações, porém para os dados de teste."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_neuralnetwork(X_sample, y_sample, nn_type, hyper_params=[1], iter_num = 10, eta=0.1):\n",
    "   \n",
    "    if not nn_type:\n",
    "        hyper_params = [1]\n",
    "    \n",
    "    acc_test_list, acc_train_list = [], []\n",
    "    N = np.shape(X_sample)[0]\n",
    "    \n",
    "    for p in hyper_params:\n",
    "        acc_test, acc_train = [], []\n",
    "\n",
    "        for _ in range(iter_num):\n",
    "            # Get indexes corresponding to each class\n",
    "            idx1 = [idx for idx, val in enumerate(y_sample.flatten()) if val==1]\n",
    "            idx0 = sorted(list(set(range(0,N)) - set(idx1)))\n",
    "            N0,N1 = len(idx0), len(idx1)\n",
    "            N_train0, N_train1 = round(0.7*N0), round(0.7*N1)\n",
    "            # Randomize indexes\n",
    "            np.random.default_rng().shuffle(idx0)\n",
    "            np.random.default_rng().shuffle(idx1)\n",
    "\n",
    "            # Select samples for training and testing\n",
    "            x_train = X_sample[np.append(idx0[0:N_train0], idx1[0:N_train1]),:]\n",
    "            x_test = X_sample[np.append(idx0[N_train0::], idx1[N_train1::]),:]\n",
    "            y_train = y_sample[np.append(idx0[0:N_train0], idx1[0:N_train1]),:]\n",
    "            y_test = y_sample[np.append(idx0[N_train0::], idx1[N_train1::]),:]\n",
    "            \n",
    "            if nn_type:\n",
    "                w, Z = train_elm(x_train, y_train, p)\n",
    "                y_hat_train = np.sign(np.tanh(x_train @ Z) @ w)\n",
    "                y_hat_test = np.sign(np.tanh(x_test @ Z) @ w)\n",
    "            else:\n",
    "                w = train_perceptron(x_train, y_train, eta=eta)\n",
    "                y_hat_train = predict_label(sigmoid(x_train @ w))\n",
    "                y_hat_test = predict_label(sigmoid(x_test @ w))\n",
    "\n",
    "            acc_train.append(eval_accuracy(y_hat_train, y_train, nn_type))\n",
    "            acc_test.append(eval_accuracy(y_hat_test, y_test, nn_type))\n",
    "            \n",
    "        acc_train_list.append((np.mean(acc_train), np.std(acc_train)))\n",
    "        acc_test_list.append((np.mean(acc_test), np.std(acc_test)))\n",
    "\n",
    "    return acc_train_list, acc_test_list"
   ]
  },
  {
   "source": [
    "\n",
    "Assim, treinou-se uma rede ELM para os hiperparâmetros $[5, 10, 30, 50, 100, 300]$, com 100 iterações para cada número de neurônios. As médias e desvios padrão das acurácias obtidas nessas iterações, para treinamento e teste, podem ser vistas a seguir:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hiperparametro: \t\ttraining accuracy:\n\t 5 \t 0.8823869346733669 ± 0.05214363322493764\n\t 10 \t 0.9384924623115577 ± 0.017281903111263295\n\t 30 \t 0.969497487437186 ± 0.007897764715911157\n\t 50 \t 0.9765326633165831 ± 0.006000976326885188\n\t 100 \t 0.9856281407035177 ± 0.003861180444683122\n\t 300 \t 0.9999748743718593 ± 0.0002499968434941212\n\nhiperparametro: \t\ttest accuracy:\n\t 5 \t 0.8762573099415204 ± 0.05624819077225214\n\t 10 \t 0.9339181286549706 ± 0.024386736212857363\n\t 30 \t 0.9597076023391813 ± 0.014056878794934904\n\t 50 \t 0.960701754385965 ± 0.01637593976438562\n\t 100 \t 0.9621637426900586 ± 0.012744111039933169\n\t 300 \t 0.8709941520467833 ± 0.02590082180204993\n"
     ]
    }
   ],
   "source": [
    "hyper_params = [5, 10, 30, 50, 100, 300]\n",
    "acc_train_list, acc_test_list = iterate_neuralnetwork(X_sample, y_sample, 1, hyper_params, 100)\n",
    "\n",
    "print('hiperparametro: \\t\\ttraining accuracy:')\n",
    "for i,j in zip(hyper_params, acc_train_list):\n",
    "    print('\\t',i,'\\t',j[0],'±',j[1])\n",
    "print('\\nhiperparametro: \\t\\ttest accuracy:')\n",
    "for i,j in zip(hyper_params, acc_test_list):\n",
    "    print('\\t',i,'\\t',j[0],'±',j[1])"
   ]
  },
  {
   "source": [
    "Conforme se aumenta o número de neurônios, a acurácia para os dados de treinamento se torna cada vez melhor, porém, para os dados de teste, isso não é verdade. Apesar da acurácia nos testes melhorar até $100$ neurônios, nota-se *overfitting* para o próximo hiperparâmetro, $300$, para o qual se obteve uma acurácia de aproximadamente $100\\%$ nos dados de treinamento, enquanto para os dados de teste essa acurácia cai para $87\\%$ aproximadamente, o que em relação ao hiperparâmetro anterior, equivale à uma queda de $9\\%$ de precisão.\n",
    "\n",
    "Por meio dos resultados acima, pode-se estimar que a acurácia máxima é obtida pelo hiperparâmetro $100$, uma vez que a acurácia, nos dados de teste, para esse número foi a melhor dentre os avaliados: $(96.2\\pm1.3\\%)$. Porém, o verdadeiro máximo repousa entre 50 e 300, valores que englobam o máximo obtido anteriormente, assim, como forma de se obter uma melhor estimativa para o número de neurônios que fornece a máxima acurácia, itera-se novamente a rede ELM para todos os hiperparâmetro entre 50 e 300, tomando-se um número de execuções igual a 10 e se obtém o número de neurônios correspondente à máxima acurácia obtida:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "52 (0.9701754385964911, 0.009591356413366494)\n"
     ]
    }
   ],
   "source": [
    "hyper_params = np.arange(50,300)\n",
    "acc_train_list, acc_test_list = iterate_neuralnetwork(X_sample, y_sample, 1, hyper_params)\n",
    "\n",
    "idx = np.argmax(acc_test_list)//2\n",
    "print(hyper_params[idx], acc_test_list[idx])"
   ]
  },
  {
   "source": [
    "\n",
    "Por meio dessas novas iterações, obteve-se a máxima acurácia nos dados de teste para o hiperparâmetro $52$, equivalente a $(97\\pm0.1)\\%$. Sendo assim, permite-se dizer que o número aproximado de neurônios para maximização da acurácia é $52$, porém seria necessário a utilização de um conjunto para validação cruzada para se determinar com maior certeza o hiperparâmetro ótimo para essa base de dados.\n",
    "\n",
    "### Perceptron\n",
    "De forma a se avaliar a eficácia da rede ELM para dados reais, treinou-se uma rede do tipo perceptron para a mesma base de dados, já normalizada e com dados desprezados, da mesma forma que anteriormente. Iterou-se, também, 100 vezes o treinamento, tomando-se ao final a média e desvio padrão das acurácias nos dados de treinamento e teste.\n",
    "\n",
    "Uma vez que o perceptron implementado se baseia na função de ativação logística, cuja imagem é $(0,1)$, necessitou-se reverter a alteração das classes de saída, assim as saídas iguais a $-1$, tornaram-se novamente $0$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training accuracy:\n0.979070351758794 ± 0.00474142639023691\n\ntest accuracy:\n0.9717543859649124 ± 0.01125043459826513\n"
     ]
    }
   ],
   "source": [
    "y_samplep = np.copy(y_sample)\n",
    "y_samplep[y_samplep == -1] = 0\n",
    "acc_train_list, acc_test_list = iterate_neuralnetwork(X_sample, y_samplep, 0, iter_num=100, eta=0.1)\n",
    "\n",
    "print('training accuracy:')\n",
    "print(acc_train_list[0][0], '±', acc_train_list[0][1])\n",
    "print('\\ntest accuracy:')\n",
    "print(acc_test_list[0][0],'±',acc_test_list[0][1])"
   ]
  },
  {
   "source": [
    "\n",
    "Percebe-se então, que o desempenho do perceptron foi superior ao desempenho da ELM. Mesmo a melhor acurácia encontrada para ELM, $(97\\pm0.1)\\%$, é inferior à obtida pelo perceptron: $(97.2\\pm 1.1)\\%$. Ambas as redes obtiveram acurácias similares, porém ao se considerar os resultados com mais iterações para a ELM, obteve-se uma acurácia $1\\%$ menor que a do perceptron, sendo os desvios padrão bastante próximos. Feita essas observações, pode-se concluir que, para essa base de dados, os dois tipos de rede estudados são eficazes, sendo o perceptron levemente superior.\n",
    "\n",
    "## Statlog (Heart)\n",
    "### ELM\n",
    "\n",
    "A base de dados foi baixada do site fornecido. Armazenou-se os dados e plotou-se a matriz de correlação de forma a se avaliar quais variáveis são de fato importantes:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/svg+xml": "<svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"600\" style=\"\" viewBox=\"0 0 600 600\"><rect x=\"0\" y=\"0\" width=\"600\" height=\"600\" style=\"fill: rgb(255, 255, 255); fill-opacity: 1;\"/><defs id=\"defs-471665\"><g class=\"clips\"><clipPath id=\"clip471665xyplot\" class=\"plotclip\"><rect width=\"280\" height=\"271\"/></clipPath><clipPath class=\"axesclip\" id=\"clip471665x\"><rect x=\"226\" y=\"0\" width=\"280\" height=\"600\"/></clipPath><clipPath class=\"axesclip\" id=\"clip471665y\"><rect x=\"0\" y=\"100\" width=\"600\" height=\"271\"/></clipPath><clipPath class=\"axesclip\" id=\"clip471665xy\"><rect x=\"226\" y=\"100\" width=\"280\" height=\"271\"/></clipPath></g><g class=\"gradients\"><linearGradient x1=\"0\" x2=\"0\" y1=\"1\" y2=\"0\" id=\"g471665-cb033b14\"><stop offset=\"0%\" stop-color=\"rgb(214, 249, 207)\" stop-opacity=\"1\"/><stop offset=\"9.090909090909092%\" stop-color=\"rgb(186, 228, 174)\" stop-opacity=\"1\"/><stop offset=\"18.181818181818183%\" stop-color=\"rgb(156, 209, 143)\" stop-opacity=\"1\"/><stop offset=\"27.27272727272727%\" stop-color=\"rgb(124, 191, 115)\" stop-opacity=\"1\"/><stop offset=\"36.36363636363637%\" stop-color=\"rgb(85, 174, 91)\" stop-opacity=\"1\"/><stop offset=\"45.45454545454545%\" stop-color=\"rgb(37, 157, 81)\" stop-opacity=\"1\"/><stop offset=\"54.54545454545454%\" stop-color=\"rgb(7, 138, 78)\" stop-opacity=\"1\"/><stop offset=\"63.63636363636363%\" stop-color=\"rgb(13, 117, 71)\" stop-opacity=\"1\"/><stop offset=\"72.72727272727273%\" stop-color=\"rgb(23, 95, 61)\" stop-opacity=\"1\"/><stop offset=\"81.81818181818183%\" stop-color=\"rgb(25, 75, 49)\" stop-opacity=\"1\"/><stop offset=\"90.9090909090909%\" stop-color=\"rgb(23, 55, 35)\" stop-opacity=\"1\"/><stop offset=\"100%\" stop-color=\"rgb(17, 36, 20)\" stop-opacity=\"1\"/></linearGradient></g></defs><g class=\"bglayer\"><rect class=\"bg\" x=\"226\" y=\"100\" width=\"280\" height=\"271\" style=\"fill: rgb(229, 236, 246); fill-opacity: 1; stroke-width: 0;\"/></g><g class=\"layer-below\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"cartesianlayer\"><g class=\"subplot xy\"><g class=\"layer-subplot\"><g class=\"shapelayer\"/><g class=\"imagelayer\"/></g><g class=\"gridlayer\"><g class=\"x\"><path class=\"xgrid crisp\" transform=\"translate(236,0)\" d=\"M0,100v271\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(256,0)\" d=\"M0,100v271\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(276,0)\" d=\"M0,100v271\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(296,0)\" d=\"M0,100v271\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(316,0)\" d=\"M0,100v271\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(336,0)\" d=\"M0,100v271\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(356,0)\" d=\"M0,100v271\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(376,0)\" d=\"M0,100v271\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(396,0)\" d=\"M0,100v271\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(416,0)\" d=\"M0,100v271\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(436,0)\" d=\"M0,100v271\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(456,0)\" d=\"M0,100v271\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(476,0)\" d=\"M0,100v271\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"xgrid crisp\" transform=\"translate(496,0)\" d=\"M0,100v271\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g><g class=\"y\"><path class=\"ygrid crisp\" transform=\"translate(0,361.32)\" d=\"M226,0h280\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,341.96000000000004)\" d=\"M226,0h280\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,322.61)\" d=\"M226,0h280\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,303.25)\" d=\"M226,0h280\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,283.89)\" d=\"M226,0h280\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,264.53999999999996)\" d=\"M226,0h280\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,245.18)\" d=\"M226,0h280\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,225.82)\" d=\"M226,0h280\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,206.45999999999998)\" d=\"M226,0h280\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,187.11)\" d=\"M226,0h280\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,167.75)\" d=\"M226,0h280\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,148.39)\" d=\"M226,0h280\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,129.04)\" d=\"M226,0h280\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/><path class=\"ygrid crisp\" transform=\"translate(0,109.68)\" d=\"M226,0h280\" style=\"stroke: rgb(255, 255, 255); stroke-opacity: 1; stroke-width: 1px;\"/></g></g><g class=\"zerolinelayer\"/><path class=\"xlines-below\"/><path class=\"ylines-below\"/><g class=\"overlines-below\"/><g class=\"xaxislayer-below\"/><g class=\"yaxislayer-below\"/><g class=\"overaxes-below\"/><g class=\"plot\" transform=\"translate(226,100)\" clip-path=\"url('#clip471665xyplot')\"><g class=\"heatmaplayer mlayer\"><g class=\"hm\"><image xmlns=\"http://www.w3.org/2000/svg\" preserveAspectRatio=\"none\" height=\"271\" width=\"280\" x=\"0\" y=\"0\" xlink:href=\"data:image/png;base64,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\" style=\"opacity: 1;\"/></g></g></g><g class=\"overplot\"/><path class=\"xlines-above crisp\" style=\"fill: none;\" d=\"M0,0\"/><path class=\"ylines-above crisp\" style=\"fill: none;\" d=\"M0,0\"/><g class=\"overlines-above\"/><g class=\"xaxislayer-above\"><g class=\"xtick\"><text text-anchor=\"end\" x=\"-2.0999999999999996\" y=\"380.4\" transform=\"translate(236,0) rotate(-90,-2.0999999999999996,374.4)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[0]age</text></g><g class=\"xtick\"><text text-anchor=\"end\" x=\"-2.0999999999999996\" y=\"380.4\" transform=\"translate(256,0) rotate(-90,-2.0999999999999996,374.4)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[1]sex</text></g><g class=\"xtick\"><text text-anchor=\"end\" x=\"-2.0999999999999996\" y=\"380.4\" transform=\"translate(276,0) rotate(-90,-2.0999999999999996,374.4)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[2]chest pain type</text></g><g class=\"xtick\"><text text-anchor=\"end\" x=\"-2.0999999999999996\" y=\"380.4\" transform=\"translate(296,0) rotate(-90,-2.0999999999999996,374.4)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[3]resting blood pressure</text></g><g class=\"xtick\"><text text-anchor=\"end\" x=\"-2.0999999999999996\" y=\"380.4\" transform=\"translate(316,0) rotate(-90,-2.0999999999999996,374.4)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[4]serum cholestoral in mg/dl</text></g><g class=\"xtick\"><text text-anchor=\"end\" x=\"-2.0999999999999996\" y=\"380.4\" transform=\"translate(336,0) rotate(-90,-2.0999999999999996,374.4)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[5]fasting blood sugar > 120 mg/dl</text></g><g class=\"xtick\"><text text-anchor=\"end\" x=\"-2.0999999999999996\" y=\"380.4\" transform=\"translate(356,0) rotate(-90,-2.0999999999999996,374.4)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[6]resting electrocardiographic results</text></g><g class=\"xtick\"><text text-anchor=\"end\" x=\"-2.0999999999999996\" y=\"380.4\" transform=\"translate(376,0) rotate(-90,-2.0999999999999996,374.4)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[7]maximum heart rate achieved</text></g><g class=\"xtick\"><text text-anchor=\"end\" x=\"-2.0999999999999996\" y=\"380.4\" transform=\"translate(396,0) rotate(-90,-2.0999999999999996,374.4)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[8]exercise induced angina</text></g><g class=\"xtick\"><text text-anchor=\"end\" x=\"-2.0999999999999996\" y=\"380.4\" transform=\"translate(416,0) rotate(-90,-2.0999999999999996,374.4)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[9]oldpeak</text></g><g class=\"xtick\"><text text-anchor=\"end\" x=\"-2.0999999999999996\" y=\"380.4\" transform=\"translate(436,0) rotate(-90,-2.0999999999999996,374.4)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[10]slope of the peak exercise</text></g><g class=\"xtick\"><text text-anchor=\"end\" x=\"-2.0999999999999996\" y=\"380.4\" transform=\"translate(456,0) rotate(-90,-2.0999999999999996,374.4)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[11]# of major vessels (flourosopy)</text></g><g class=\"xtick\"><text text-anchor=\"end\" x=\"-2.0999999999999996\" y=\"380.4\" transform=\"translate(476,0) rotate(-90,-2.0999999999999996,374.4)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[12]thal</text></g><g class=\"xtick\"><text text-anchor=\"end\" x=\"-2.0999999999999996\" y=\"380.4\" transform=\"translate(496,0) rotate(-90,-2.0999999999999996,374.4)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">heart disease</text></g></g><g class=\"yaxislayer-above\"><g class=\"ytick\"><text text-anchor=\"end\" x=\"225\" y=\"4.199999999999999\" transform=\"translate(0,361.32)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">heart disease</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"225\" y=\"4.199999999999999\" transform=\"translate(0,341.96000000000004)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[12]thal</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"225\" y=\"4.199999999999999\" transform=\"translate(0,322.61)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[11]# of major vessels (flourosopy)</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"225\" y=\"4.199999999999999\" transform=\"translate(0,303.25)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[10]slope of the peak exercise</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"225\" y=\"4.199999999999999\" transform=\"translate(0,283.89)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[9]oldpeak</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"225\" y=\"4.199999999999999\" transform=\"translate(0,264.53999999999996)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[8]exercise induced angina</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"225\" y=\"4.199999999999999\" transform=\"translate(0,245.18)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[7]maximum heart rate achieved</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"225\" y=\"4.199999999999999\" transform=\"translate(0,225.82)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[6]resting electrocardiographic results</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"225\" y=\"4.199999999999999\" transform=\"translate(0,206.45999999999998)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[5]fasting blood sugar > 120 mg/dl</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"225\" y=\"4.199999999999999\" transform=\"translate(0,187.11)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[4]serum cholestoral in mg/dl</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"225\" y=\"4.199999999999999\" transform=\"translate(0,167.75)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[3]resting blood pressure</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"225\" y=\"4.199999999999999\" transform=\"translate(0,148.39)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[2]chest pain type</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"225\" y=\"4.199999999999999\" transform=\"translate(0,129.04)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[1]sex</text></g><g class=\"ytick\"><text text-anchor=\"end\" x=\"225\" y=\"4.199999999999999\" transform=\"translate(0,109.68)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">[0]age</text></g></g><g class=\"overaxes-above\"/></g></g><g class=\"polarlayer\"/><g class=\"ternarylayer\"/><g class=\"geolayer\"/><g class=\"funnelarealayer\"/><g class=\"pielayer\"/><g class=\"treemaplayer\"/><g class=\"sunburstlayer\"/><g class=\"glimages\"/><defs id=\"topdefs-471665\"><g class=\"clips\"/></defs><g class=\"layer-above\"><g class=\"imagelayer\"/><g class=\"shapelayer\"/></g><g class=\"infolayer\"><g class=\"cb033b14 colorbar\" transform=\"translate(226,100)\"><rect class=\"cbbg\" x=\"286\" y=\"0\" width=\"75.9375\" height=\"271\" style=\"fill: rgb(0, 0, 0); fill-opacity: 0; stroke: rgb(68, 68, 68); stroke-opacity: 1; stroke-width: 0;\"/><g class=\"cbfills\" transform=\"translate(0,10)\"><rect class=\"cbfill\" x=\"296\" width=\"30\" y=\"0\" height=\"251\" style=\"fill: url('#g471665-cb033b14');\"/></g><g class=\"cblines\" transform=\"translate(0,10)\"/><g class=\"cbaxis crisp\" transform=\"translate(0,-100)\"><g class=\"ycb033b14tick\"><text text-anchor=\"start\" x=\"328.9\" y=\"4.199999999999999\" transform=\"translate(0,357.71999999999997)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">−0.4</text></g><g class=\"ycb033b14tick\"><text text-anchor=\"start\" x=\"328.9\" y=\"4.199999999999999\" transform=\"translate(0,322.33)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">−0.2</text></g><g class=\"ycb033b14tick\"><text text-anchor=\"start\" x=\"328.9\" y=\"4.199999999999999\" transform=\"translate(0,286.95)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0</text></g><g class=\"ycb033b14tick\"><text text-anchor=\"start\" x=\"328.9\" y=\"4.199999999999999\" transform=\"translate(0,251.56)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0.2</text></g><g class=\"ycb033b14tick\"><text text-anchor=\"start\" x=\"328.9\" y=\"4.199999999999999\" transform=\"translate(0,216.17)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0.4</text></g><g class=\"ycb033b14tick\"><text text-anchor=\"start\" x=\"328.9\" y=\"4.199999999999999\" transform=\"translate(0,180.77999999999997)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0.6</text></g><g class=\"ycb033b14tick\"><text text-anchor=\"start\" x=\"328.9\" y=\"4.199999999999999\" transform=\"translate(0,145.39)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">0.8</text></g><g class=\"ycb033b14tick\"><text text-anchor=\"start\" x=\"328.9\" y=\"4.199999999999999\" transform=\"translate(0,109.99999999999999)\" style=\"font-family: 'Open Sans', verdana, arial, sans-serif; font-size: 12px; fill: rgb(42, 63, 95); fill-opacity: 1; white-space: pre;\">1</text></g></g><g class=\"cbtitleunshift\" transform=\"translate(-226,-100)\"><g class=\"cbtitle\"/></g><rect class=\"cboutline\" x=\"296\" y=\"10\" width=\"30\" height=\"251\" style=\"stroke: rgb(68, 68, 68); stroke-opacity: 1; fill: none; stroke-width: 0;\"/></g><g class=\"g-gtitle\"/><g class=\"g-xtitle\"/><g class=\"g-ytitle\"/></g></svg>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "data = np.loadtxt( 'heart.dat' )\n",
    "X_samples = np.copy(data[:, 0:-1])\n",
    "y_sample = np.reshape(np.copy(data[:, -1]), (-1,1))\n",
    "feat_names = ['[0]age', '[1]sex','[2]chest pain type','[3]resting blood pressure','[4]serum cholestoral in mg/dl','[5]fasting blood sugar > 120 mg/dl','[6]resting electrocardiographic results','[7]maximum heart rate achieved','[8]exercise induced angina','[9]oldpeak','[10]slope of the peak exercise','[11]# of major vessels (flourosopy)','[12]thal', 'heart disease']\n",
    "\n",
    "df = pd.DataFrame(data, columns = feat_names)\n",
    "corr = df.corr()\n",
    "fig = go.Figure(go.Heatmap(z=corr.values,x=corr.index.values, y=corr.columns.values, colorscale='algae'))\n",
    "fig.update_layout(yaxis_autorange='reversed', width = 600, height = 600, xaxis= dict(tickangle = -90))\n",
    "fig.show(renderer = 'svg', width = 600, height =600)"
   ]
  },
  {
   "source": [
    "\n",
    "Analisando-se a matriz de correlação, escolheu-se ignorar os dados $4\\text{ e } 5$, cujas correlações com a classe de saída são menores, em módulo, que $0.1$.\n",
    "\n",
    "Necessita-se de alterar as classes de valor $2$ para valores iguais a $-1$, além disso, os dados claramente necessitam de normalização, uma vez que há diversas unidades e escalas diferentes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = np.shape(X_samples)[0]\n",
    "y_sample[y_sample==2] = -1\n",
    "\n",
    "X_mean = np.mean(X_samples, axis = 0)\n",
    "X_std = np.std(X_samples, axis = 0)\n",
    "X_samplen = normalize_features(X_samples, X_mean, X_std)\n",
    "\n",
    "# Remove useless features and append x0\n",
    "ignored_idx = [4,5]\n",
    "X_sample = delete_features(X_samplen, ignored_idx)\n",
    "X_sample = np.append(np.ones((N,1)), X_samplen, 1)"
   ]
  },
  {
   "source": [
    "\n",
    "Com os dados melhorados, pode-se tomar o mesmo procedimento feito para o *Breast Cancer*, utilizando-se o mesmo número de iterações:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hiperparametro: \t\ttraining accuracy:\n\t 5 \t 0.7556613756613757 ± 0.05340184144527309\n\t 10 \t 0.8218518518518519 ± 0.026969131635936953\n\t 30 \t 0.8772486772486772 ± 0.0158023116646223\n\t 50 \t 0.9040211640211641 ± 0.019555544103159794\n\t 100 \t 0.9668783068783068 ± 0.011461348256172843\n\t 300 \t 1.0 ± 0.0\n\nhiperparametro: \t\ttest accuracy:\n\t 5 \t 0.7406172839506173 ± 0.06772131044082046\n\t 10 \t 0.7909876543209877 ± 0.0459370423291322\n\t 30 \t 0.814567901234568 ± 0.03801106056793419\n\t 50 \t 0.7954320987654322 ± 0.041252121642518506\n\t 100 \t 0.7396296296296296 ± 0.0456321080509102\n\t 300 \t 0.6999999999999998 ± 0.04880838864387851\n"
     ]
    }
   ],
   "source": [
    "hyper_params = [5, 10, 30, 50, 100, 300]\n",
    "acc_train_list, acc_test_list = iterate_neuralnetwork(X_sample, y_sample, 1, hyper_params, 100)\n",
    "\n",
    "print('hiperparametro: \\t\\ttraining accuracy:')\n",
    "for i,j in zip(hyper_params, acc_train_list):\n",
    "    print('\\t',i,'\\t',j[0],'±',j[1])\n",
    "print('\\nhiperparametro: \\t\\ttest accuracy:')\n",
    "for i,j in zip(hyper_params, acc_test_list):\n",
    "    print('\\t',i,'\\t',j[0],'±',j[1])"
   ]
  },
  {
   "source": [
    "\n",
    "Para essa base de dados, o desempenho da ELM foi pior. Novamente, apesar da acurácia de treino só melhorar, o comportamento da acurácia de teste não segue esse padrão, ao alcançar um certo máximo, essa acurácia começa a decair, indicando *overfitting*. Percebe-se ainda que para 300 neurônios os dados de entrada são perfeitamente interpolados, obtendo-se o máximo de *overfitting* possível. Ainda é interessante notar que mesmo havendo perfeita interpolação dos dados com o hiperparâmetro $300$, a acurácia de testes ainda é $70\\%$.\n",
    "\n",
    "Dentre os valores analisados, o número de neurônios que permite a maximização da acurácia é $30$, sendo aproximada de $(81.5\\pm3.8)\\%$.\n",
    "\n",
    "Uma vez que o hiperparâmetro ótimo está entre $10$ e $50$, iterou-se novamente a ELM para todos esses valores, $10$ vezes para cada hiperparâmetro, de forma a se obter a máxima acurácia:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12 (0.8358024691358026, 0.0292412821785852)\n"
     ]
    }
   ],
   "source": [
    "hyper_params = np.arange(10,50)\n",
    "acc_train_list, acc_test_list = iterate_neuralnetwork(X_sample, y_sample, 1, hyper_params)\n",
    "\n",
    "idx = np.argmax(acc_test_list)//2\n",
    "print(hyper_params[idx], acc_test_list[idx])"
   ]
  },
  {
   "source": [
    "\n",
    "Com as novas iterações, obtém-se máxima acurácia para $12$ neurônios, de aproximadamente $(83.6\\pm2.9)\\%$. Dessa forma o número ótimo é aproximadamente $12$ neurônios.\n",
    "\n",
    "### Perceptron\n",
    "\n",
    "Da mesma forma que anteriormente, com os mesmos parâmetros, treinou-se a rede perceptron. Novamente, alterou-se as saídas $-1$ para valores $0$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training accuracy:\n0.8598412698412697 ± 0.01577562716225494\n\ntest accuracy:\n0.8462962962962962 ± 0.036887558440317686\n"
     ]
    }
   ],
   "source": [
    "y_samplep = np.copy(y_sample)\n",
    "y_samplep[y_samplep == -1] = 0\n",
    "acc_train_list, acc_test_list = iterate_neuralnetwork(X_sample, y_samplep, 0, iter_num=100, eta=0.1)\n",
    "\n",
    "print('training accuracy:')\n",
    "print(acc_train_list[0][0], '±', acc_train_list[0][1])\n",
    "print('\\ntest accuracy:')\n",
    "print(acc_test_list[0][0],'±',acc_test_list[0][1])"
   ]
  },
  {
   "source": [
    "Percebe-se que novamente o perceptron teve melhor desempenho que a ELM, obtendo $(84.6\\pm3.7\\%)$ de acurácia. \n",
    "\n",
    "Supõe-se que o fato do perceptron ter apresentado um ótimo desempenho para ambos os conjuntos de dados se deve ao redimensionamento da base, desprezando-se alguns dados, somado ao uso da função de custo escolhida, que pode ter fornecido um ajuste melhor devido à sua convexidade.\n",
    "\n",
    "A base de dados *Statlog* aparenta mais simples, porém, na prática essa observação não se concretizou. Não foi possível supor qualquer motivo para a piora de ambas as redes, uma vez que, mesmo utilizando todos os dados da base, o resultado da ELM e perceptron são os mesmos. Conjectura-se que pode ser possível melhorar a convergência de ambas as redes utilizando *data augmentation*, fazendo combinações entre os dados de entrada fornecidos.\n",
    "\n",
    "Com esse estudo foi possível observar a robustez de uma rede do tipo perceptron, que mesmo sem múltiplas camadas, foi capaz de ter melhor desempenho que as ELMs. Notou-se também a eficácia das ELMs, que, mesmo projetando os dados de forma aleatória na camada intermediária, são capazes de classificar muito bem conjuntos reais de dados. \n",
    "\n",
    "Supõe-se ainda que a opção por uma rede perceptron ou ELM pode ser analisada pela complexidade da base de dados. Dependendo da separabilidade do conjunto, é possível que uma rede ELM necessite de um número exagerado de neurônios na camada intermediária, resultando em uma maior complexidade do que um simples perceptron. Da mesma forma, para bases mais simples, redes ELM são interessantes por não necessitarem de várias iterações, obtendo aproximações de forma direta, diferentemente do perceptron. Ou seja, a escolha do modelo de rede se dá não pelo modelo, mas sim pelos dados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}